{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JiahuaQu/conga/blob/master/TCRdist_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Please note this is an experimental code for accelerated TCRdist computation on CPU and GPU`**\n",
        "\n",
        "It was not extensively tested. Before usage upload params_v2.tsv, tmp_tcr.tsv and TCRdist_matrix_mega.tsv.\n",
        "\n",
        "contact: mikhail.pogorelyy@stjude.org (Mikhail Pogorelyy)"
      ],
      "metadata": {
        "id": "vYV-Cya44oYh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FohaCljb38sR"
      },
      "outputs": [],
      "source": [
        "import cupy as mx #cuda python backend, connect to T4 runtime or other with GPU\n",
        "import numpy as np\n",
        "#import numpy as mx #use this for CPU only\n",
        "#import mlx.core as mx #use this for apple silicon\n",
        "import pandas as pd\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_center(seq, target_length): # function to pad center with gaps until target length\n",
        "   seq_length = len(seq)\n",
        "   if seq_length >= target_length:\n",
        "       return seq[:target_length]\n",
        "   else:\n",
        "       total_padding = target_length - seq_length\n",
        "       first_half = seq[:seq_length // 2]\n",
        "       second_half = seq[seq_length // 2:]\n",
        "       return first_half + ['_'] * total_padding + second_half\n",
        "\n",
        "#load TCR file\n",
        "tst_tcr = pd.read_csv(\"tmp_tcr.tsv\", sep=\"\\t\")\n",
        "\n",
        "#load encoder dictionary\n",
        "params_df = pd.read_csv(\"params_v2.tsv\", sep=\"\\t\", header=None, names=[\"feature\", \"value\"])\n",
        "params_vec = dict(zip(params_df[\"feature\"], params_df[\"value\"]))\n",
        "#load substitution matrix\n",
        "submat = mx.array(np.loadtxt('TCRdist_matrix_mega.tsv', delimiter='\\t', dtype=np.int16)) #this is substitution matrix\n",
        "\n",
        "#encode TCRs\n",
        "cdr3amat = np.array([pad_center(list(seq), 29) for seq in tst_tcr['cdr3a']])\n",
        "cdr3amatint = np.vectorize(params_vec.get)(cdr3amat)\n",
        "cdr3bmat = np.array([pad_center(list(seq), 29) for seq in tst_tcr['cdr3b']])\n",
        "cdr3bmatint = np.vectorize(params_vec.get)(cdr3bmat)\n",
        "\n",
        "cols_to_use = slice(3, -2) #truncate CDR3s\n",
        "\n",
        "encoded = np.column_stack([\n",
        "    np.vectorize(params_vec.get)(tst_tcr['va']),\n",
        "    cdr3amatint[:,cols_to_use],\n",
        "    np.vectorize(params_vec.get)(tst_tcr['vb']),\n",
        "    cdr3bmatint[:,cols_to_use]\n",
        "])\n"
      ],
      "metadata": {
        "id": "iSXY-MhR4Llx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert to cupy arrays if cupy imported\n",
        "tcrs1=mx.array(encoded).astype(mx.uint8)\n",
        "tcrs2=mx.array(encoded).astype(mx.uint8) # could be a different dataset, like a database\n",
        "\n",
        "kbest=1000 # nbest neighbour we are looking for\n",
        "chunk_size=min(tcrs1.shape[0],20000000//tcrs2.shape[0]) # decrease magic constant to limit memory consumption by temporaty 3d tensor. Increase if you have more powerful gpu\n",
        "print('total number of chunks', tcrs1.shape[0]//chunk_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jeYjCkr5zQT",
        "outputId": "4a01acbb-1d4a-4f75-84e2-7413ea19957b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of chunks 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tcrs1.shape # (20000, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTRokxiC7_qp",
        "outputId": "293c0f0e-c3ca-46c1-d8fd-09316f8e2648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "result=mx.zeros((tcrs1.shape[0],kbest),dtype=mx.uint32) #initialize result array for indices\n",
        "for ch in range(0, tcrs1.shape[0], chunk_size): #we process in chunks across tcr1 to not run out of memory\n",
        "    #print('Processing chunk', ch)\n",
        "    chunk_end = min(ch + chunk_size, tcrs1.shape[0])\n",
        "    row_range = slice(ch, chunk_end)\n",
        "    #mx.sum(submat[tcrs1[row_range, None, :], tcrs2[ None,:, :]],axis=2)# if you just want TCRdist matrix for this chunk\n",
        "    result[row_range,:]=mx.argpartition(mx.sum(submat[tcrs1[row_range, None, :], tcrs2[ None,:, :]],axis=2),axis=1,kth=kbest)[:,0:kbest] #note that this does not guarantee elements are sorted within partition! It is also annoying that sum produce 32 bit ints here, 16 bit would be enough\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(result)\n",
        "print(f\"Time taken: {end_time - start_time:.6f} seconds\") #6.7 seconds on T4 GPU, 120 seconds on T4 CPU\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iu9lU5c6CWW",
        "outputId": "08d03e42-90a0-4067-bc8b-d8e91df87b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[    0  8427 16854 ... 17448 17501 18398]\n",
            " [    1  8428 16855 ... 18036 18181 18283]\n",
            " [    2  8429 16856 ... 10387 11150 11254]\n",
            " ...\n",
            " [ 3143 11570 19997 ...  6140  6744  7490]\n",
            " [ 3144 11571 19998 ... 15842 16659 16994]\n",
            " [ 3145 11572 19999 ...  9970 10082 11150]]\n",
            "Time taken: 6.797993 seconds\n"
          ]
        }
      ]
    }
  ]
}